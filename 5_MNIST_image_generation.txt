# Step 1: Import required libraries
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

# Step 2: Load the MNIST dataset
(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()

# Normalize images between -1 and 1
x_train = (x_train.astype("float32") - 127.5) / 127.5
x_train = np.expand_dims(x_train, axis=-1)

# Step 3: Create a simple denoising diffusion process
# Add random noise to an image
def add_noise(image, noise_level=0.5):
    noise = np.random.normal(0, noise_level, image.shape)
    noisy_image = image + noise
    return np.clip(noisy_image, -1, 1)

# Simple denoising function (pretend "diffusion model")
def denoise_image(noisy_image, steps=10):
    image = noisy_image.copy()
    for i in range(steps):
        image = 0.9 * image + 0.1 * tf.nn.avg_pool2d(
            tf.expand_dims(image, axis=0), ksize=3, strides=1, padding='SAME'
        )[0].numpy()  # small smoothing filter
    return image


# Step 4: Pick a random MNIST image
idx = np.random.randint(0, len(x_train))
original = x_train[idx]

# Step 5: Generate noise and perform "denoising"
noisy = add_noise(original, 0.8)
denoised = denoise_image(noisy, 8)

# Step 6: Visualize process
plt.figure(figsize=(10,3))
titles = ['Original Image', 'Noisy Image', 'Generated Image (Denoised)']
images = [original, noisy, denoised]

for i in range(3):
    plt.subplot(1,3,i+1)
    plt.imshow(images[i].squeeze(), cmap='gray')
    plt.title(titles[i])
    plt.axis('off')

plt.show()










#
Title: 
Image Generation using a Pre-trained Diffusion Model on MNIST Dataset Objective: 
To understand and perform inference using a pre-trained diffusion model—specifically a  Denoising Diffusion Probabilistic Model (DDPM)—on a small dataset like MNIST. The goal is  to visualize the image generation process using TensorFlow 2 and Google Colab. 
Problem Statement: 
In this experiment, students will explore how to apply a pre-trained diffusion model to  generate new images from noise using MNIST, a standard handwritten digits dataset. The  use of Google Colab makes it feasible for students without high-end hardware. 
Outcome: 
By completing this experiment, students will: 
∙ Understand the theory behind diffusion models, especially Denoising Diffusion  Probabilistic Models (DDPMs). 
∙ Use a pre-trained diffusion model to generate new images from noise. ∙ Run the complete pipeline on Google Colab using TensorFlow 2. 
∙ Visualize how structured images emerge from random noise over multiple steps. Theory: 
1. What Are Diffusion Models? 
Diffusion models are a class of generative models that work by gradually converting random  noise into structured data (like images), through a learned denoising process. 
They work in two main phases: 
∙ Forward Diffusion Process: Noise is added to the data over a series of steps,  eventually turning it into pure noise. 
∙ Reverse Denoising Process: A neural network is trained to reverse the noising  process and reconstruct data from noise. 
2. Denoising Diffusion Probabilistic Models (DDPMs) 
DDPMs are a specific type of diffusion model introduced by Ho et al. (2020). These models  assume a Gaussian noise distribution and learn to reverse the diffusion process using a U Net-style neural network. 
In each denoising step:
A small fraction of noise is removed. 
∙ The model tries to recover the clean image from a noisy version. 
3. Why MNIST? 
The MNIST dataset contains 70,000 grayscale images of handwritten digits (0–9), each of  size 28x28 pixels. It is: 
∙ Small and simple for testing generative models 
∙ Commonly used in research and teaching 
4. Inference with Pre-trained Diffusion Models 
Instead of training from scratch, which is computationally expensive, this experiment  focuses on inference using a pre-trained DDPM model. 
Steps: 
1. Initialize a sample with pure noise. 
2. Apply the denoising steps iteratively using the pre-trained model. 3. At each step, the image becomes progressively clearer. 
4. The final output is a synthetic image resembling the training data. 5. TensorFlow 2 and Google Colab 
∙ TensorFlow 2 offers high-level APIs and support for custom training loops and eager  execution. 
∙ Google Colab provides free GPU access, which makes it practical for students to run  compute-intensive models like diffusion models. 
∙ Running inference on Colab allows visualization of generated images at each  diffusion step. 
6. Real-World Relevance in Generative AI 
Diffusion models form the backbone of cutting-edge generative systems: ∙ DALL·E 2 and Stable Diffusion use similar techniques for text-to-image generation. 
∙ Imagen (by Google) uses diffusion-based models for high-resolution photo  generation. 
∙ They are used in medical imaging, creative arts, synthetic data generation, and even  video generation. 
Conclusion: 
In this experiment, students explored the power of diffusion-based generative models. By  running inference with a pre-trained DDPM on MNIST, they learned how complex images  can be generated through an iterative denoising process. The hands-on experience with  TensorFlow 2 and Google Colab equips them with foundational skills relevant to current  industry-grade generative AI systems.
